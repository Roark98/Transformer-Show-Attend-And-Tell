# Transformer Show Attend And Tell
This repository contains an adaptation of the architecture proposed by the [Show, Attend and Tell](https://arxiv.org/pdf/1502.03044.pdf) paper. Our proposal focuses on replacing the convolutional component used by its original encoder by a structure based on Transformer networks. This contribution was respectively documented in the paper [Deep Learning Approaches Based on Transformer Architectures for Image Captioning Tasks](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9739703).

## Description of the main files

## Dataset

The 2014 version of the COCO dataset was used for this work. The [Training](http://images.cocodataset.org/zips/train2014.zip) and [Validation](http://images.cocodataset.org/zips/val2014.zip) sets can be found in the attached links.

## Training and Inference
